# Claim Auditor

**Automated earnings verification system that fact-checks executive claims from earnings calls.**

Executives make 30-50 quantitative claims per earnings call. This system extracts them via LLM, verifies against SEC data, and detects patterns of misleading communication.

**ðŸ”— [Live Demo](https://claim-auditor.streamlit.app/)**\
**ðŸŽ¥ [Demo Video](https://youtu.be/coming-soon)** *(Coming soon!)*

---

## Problem & Solution

### The Problem

During quarterly earnings calls, executives make claims like:
- *"Revenue grew 15% year-over-year"*
- *"Operating margins expanded to 28%"*
- *"Free cash flow was $4.2 billion"*

**But:**
- Often inaccurate (stated 15%, actual was 12.3%)
- Sometimes misleading (GAAP vs non-GAAP switching, favorable rounding)
- Systematically biased (consistent patterns across quarters)

Manual verification is impracticalâ€”requires cross-referencing multiple financial statements, unit conversions, and pattern detection.

### The Solution

Automated 4-stage pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   INGEST     â”‚ â†’ â”‚   EXTRACT    â”‚ â†’ â”‚   VERIFY     â”‚ â†’ â”‚   ANALYZE    â”‚
â”‚              â”‚   â”‚              â”‚   â”‚              â”‚   â”‚              â”‚
â”‚ Fetch data   â”‚   â”‚ LLM extracts â”‚   â”‚ Compare vs   â”‚   â”‚ Detect cross-â”‚
â”‚ from FMP API â”‚   â”‚ structured   â”‚   â”‚ actual data  â”‚   â”‚ quarter      â”‚
â”‚ & store in   â”‚   â”‚ claims from  â”‚   â”‚ & assign     â”‚   â”‚ patterns of  â”‚
â”‚ SQLite       â”‚   â”‚ transcripts  â”‚   â”‚ verdicts     â”‚   â”‚ deception    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Output:** Trust scores (0-100), verdict breakdowns, discrepancy patterns, and a web dashboard.

---

## Key Features

### 1. Multi-Tier Verdict System

Not just true/falseâ€”captures nuance:

| Verdict | Threshold | Example |
|---------|-----------|---------|
| âœ… Correct | Within 2% | Stated 15.1%, actual 15.0% |
| â‰ˆ Mostly Correct | Within 10% | Stated 15%, actual 13.8% |
| âš ï¸ Misleading | 10-25% off OR flagged | Stated 15%, actual 11.2% |
| âŒ Incorrect | >25% off | Stated 15%, actual 9.8% |
| â“ Cannot Verify | No data | Segment claim without segment data |

### 2. Pattern Detection

Detects systematic deception across quarters:
- **Consistent rounding up** (>70% of claims favor company)
- **Metric switching** (emphasizing different metrics each quarter)
- **Increasing inaccuracy** (accuracy declining over time)
- **GAAP shifting** (switching between GAAP and non-GAAP)
- **Selective emphasis** (only mentioning positive metrics)

### 3. Multiple Interfaces

- **Streamlit Dashboard** - Visual exploration
- **REST API** - Programmatic access (12 endpoints)
- **CLI** - Pipeline execution
- **MCP Server** - AI agent integration

### 4. Smart Transcript Fallback (Three-Tier Strategy)

When transcript data is unavailable from FMP API:

1. **Tier 1:** Fetch from FMP API (primary source)
2. **Tier 2:** Load from local files (`data/transcripts/`)
3. **Tier 3:** Generate with LLM based on financial data (automatic fallback)

The system automatically generates realistic earnings call transcripts using Claude when needed, ensuring no company is left without claims to audit.

### 5. Production-Ready

- **333+ tests** passing (unit + integration + E2E)
- **6-layer clean architecture** with dependency injection
- **Service-controlled transactions** (atomicity, rollback, data consistency)
- **Structured logging** (JSON/human-readable modes)
- **Health checks** (Kubernetes-ready probes)
- **API versioning** (/api/v1/) with backward compatibility
- **Input validation** (Pydantic models prevent injection attacks)
- **Database migrations** (Alembic for safe schema evolution)
- **Docker-first** deployment (same image for UI/API)
- **Comprehensive docs** (readme, architecture, setup, API guide)

---

## Quick Start (5 Minutes)

### Prerequisites

- Docker & Docker Compose
- API keys: [FMP](https://financialmodelingprep.com) (free) + [Anthropic](https://console.anthropic.com)

### Setup

```bash
cd claim-auditor/backend

# 1. Configure API keys
cat > .env << EOF
FMP_API_KEY=your_fmp_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
EOF

# 2. Run pipeline (populate database)
docker compose run streamlit python -m scripts.run_pipeline

# 3. Launch UI
docker compose up streamlit
```

**Access:** http://localhost:8501

---

## Project Structure

```
claim-auditor/
â”œâ”€â”€ README.md                    â† You are here
â”œâ”€â”€ docs/                        â† Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE_GUIDE.md          â†’ Deep dive: layers, design decisions
â”‚   â”œâ”€â”€ SETUP_GUIDE.md                 â†’ Setup & deployment guide
â”‚   â”œâ”€â”€ API_USAGE_GUIDE.md                   â†’ REST API guide with examples
â”‚   â””â”€â”€ MCP_GUIDE.md                   â†’ AI agent integration
â”‚
â””â”€â”€ backend/
    â”œâ”€â”€ Dockerfile               â† Container definition
    â”œâ”€â”€ docker-compose.yml       â† Multi-service orchestration
    â”œâ”€â”€ requirements.txt         â† Python dependencies
    â”‚
    â”œâ”€â”€ app/                     â† Core application
    â”‚   â”œâ”€â”€ main.py              â† FastAPI application entry point
    â”‚   â”œâ”€â”€ facade.py            â† Single entry point (hides complexity)
    â”‚   â”œâ”€â”€ container.py         â† Dependency injection container
    â”‚   â”œâ”€â”€ logging_config.py    â† Structured logging setup
    â”‚   â”œâ”€â”€ health.py            â† Health check endpoints
    â”‚   â”‚
    â”‚   â”œâ”€â”€ clients/             â† External API wrappers
    â”‚   â”‚   â”œâ”€â”€ fmp_client.py    â†’ Financial data API
    â”‚   â”‚   â””â”€â”€ llm_client.py    â†’ Claude AI
    â”‚   â”‚
    â”‚   â”œâ”€â”€ services/            â† Workflow orchestration
    â”‚   â”‚   â”œâ”€â”€ ingestion_service.py
    â”‚   â”‚   â”œâ”€â”€ extraction_service.py
    â”‚   â”‚   â”œâ”€â”€ verification_service.py
    â”‚   â”‚   â””â”€â”€ analysis_service.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ engines/             â† Core business logic
    â”‚   â”‚   â”œâ”€â”€ claim_extractor.py
    â”‚   â”‚   â”œâ”€â”€ verification_engine.py  â† 400+ lines, core algorithm
    â”‚   â”‚   â”œâ”€â”€ metric_mapper.py
    â”‚   â”‚   â””â”€â”€ discrepancy_analyzer.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ domain/              â† Pure business rules (zero dependencies)
    â”‚   â”‚   â”œâ”€â”€ metrics.py       â†’ Metric definitions
    â”‚   â”‚   â”œâ”€â”€ verdicts.py      â†’ Verdict assignment logic
    â”‚   â”‚   â””â”€â”€ scoring.py       â†’ Trust score formulas
    â”‚   â”‚
    â”‚   â”œâ”€â”€ repositories/        â† Database abstraction
    â”‚   â”œâ”€â”€ models/              â† SQLAlchemy ORM (database tables)
    â”‚   â”œâ”€â”€ schemas/             â† Pydantic (API contracts + validation)
    â”‚   â”‚   â””â”€â”€ pipeline.py      â†’ Pipeline request validation
    â”‚   â””â”€â”€ api/                 â† REST API endpoints
    â”‚       â”œâ”€â”€ pipeline.py      â†’ Pipeline operations
    â”‚       â”œâ”€â”€ companies.py     â†’ Company endpoints
    â”‚       â”œâ”€â”€ claims.py        â†’ Claim endpoints
    â”‚       â””â”€â”€ transcripts.py   â†’ Transcript endpoints
    â”‚
    â”œâ”€â”€ alembic/                 â† Database migrations
    â”‚   â”œâ”€â”€ versions/            â†’ Migration scripts
    â”‚   â””â”€â”€ env.py               â†’ Alembic configuration
    â”‚
    â”œâ”€â”€ streamlit_app.py         â† Web dashboard
    â”œâ”€â”€ mcp_server.py            â† AI agent integration
    â”œâ”€â”€ scripts/run_pipeline.py â† CLI entry point
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ claim_auditor.db     â† SQLite database
    â”‚   â”œâ”€â”€ fmp_cache/           â† API response cache
    â”‚   â””â”€â”€ transcripts/         â† Local transcript files
    â”‚
    â””â”€â”€ tests/
        â”œâ”€â”€ unit/                â† Fast tests (313+ tests, <3s)
        â”œâ”€â”€ api/                 â† API endpoint tests
        â””â”€â”€ integration/         â† Live API tests
```

---

## Usage

### Run Pipeline

```bash
# With Docker (recommended)
docker compose run streamlit python -m scripts.run_pipeline

# Run specific step
docker compose run streamlit python -m scripts.run_pipeline --step extract

# Target specific companies
docker compose run streamlit python -m scripts.run_pipeline --tickers AAPL MSFT
```

### Launch Interfaces

```bash
# Streamlit Dashboard
docker compose up streamlit
# â†’ http://localhost:8501

# REST API
docker compose up api
# â†’ http://localhost:8000/docs (interactive Swagger UI)

# Both
docker compose up
```

### Run Tests

```bash
# All tests
docker compose run streamlit pytest

# With coverage
docker compose run streamlit pytest --cov=app --cov-report=term-missing

# Specific test file
docker compose run streamlit pytest tests/unit/test_verification_engine.py
```

---

## REST API

**Base URL (v1):** http://localhost:8000/api/v1
**Legacy:** http://localhost:8000/api (backward compatible)

### Key Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /api/v1/companies/` | List all companies with stats |
| `GET /api/v1/companies/{ticker}` | Full analysis for one company |
| `GET /api/v1/claims/` | List claims (filterable by verdict/metric/ticker) |
| `GET /api/v1/transcripts/` | List transcripts |
| `GET /api/v1/pipeline/status` | Pipeline status (counts) |
| `POST /api/v1/pipeline/ingest` | Fetch data from FMP API |
| `POST /api/v1/pipeline/extract` | Extract claims via LLM |
| `POST /api/v1/pipeline/verify` | Verify claims against data |
| `POST /api/v1/pipeline/analyze` | Detect discrepancy patterns |
| `POST /api/v1/pipeline/run-all` | Execute full pipeline |
| `GET /health` | Basic health check |
| `GET /health/detailed` | Health check with dependencies |
| `GET /health/ready` | Kubernetes readiness probe |
| `GET /health/live` | Kubernetes liveness probe |

### Examples

```bash
# Get all companies
curl http://localhost:8000/api/v1/companies/

# Analyze Amazon
curl http://localhost:8000/api/v1/companies/AMZN

# Get misleading claims
curl "http://localhost:8000/api/v1/claims/?verdict=MISLEADING"

# Check health
curl http://localhost:8000/health/detailed

# Trigger ingestion
curl -X POST http://localhost:8000/api/v1/pipeline/ingest \
  -H "Content-Type: application/json" \
  -d '{"tickers": ["AAPL"], "quarters": [[2025, 4]]}'
```

**Full docs:** Visit http://localhost:8000/docs for interactive API documentation

**More examples:** [docs/API_USAGE_GUIDE.md](docs/API_USAGE_GUIDE.md) - Comprehensive API guide with curl/Python/JavaScript examples

**Setup guide:** [docs/SETUP_GUIDE.md](docs/SETUP_GUIDE.md) - Comprehensive setup, deployment, and troubleshooting

---

## Tech Stack

| Layer | Technology |
|-------|------------|
| **Language** | Python 3.13 |
| **Web Framework** | FastAPI (API), Streamlit (UI) |
| **LLM** | Claude Sonnet 4.5 (Anthropic) |
| **Financial Data** | Financial Modeling Prep API |
| **Database** | SQLite (dev), PostgreSQL-ready |
| **ORM** | SQLAlchemy 2.0 |
| **Migrations** | Alembic |
| **Validation** | Pydantic 2.0 |
| **Logging** | structlog (JSON/human-readable) |
| **Dependency Injection** | dependency-injector |
| **Testing** | pytest, pytest-cov (331+ tests) |
| **Deployment** | Docker, docker-compose |
| **CI/CD** | GitHub Actions (can be added) |

---

## Architecture Highlights

### System Architecture (High Level)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Multiple Interfaces                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Streamlit â”‚  â”‚ REST API â”‚  â”‚ CLI      â”‚  â”‚ MCP Server   â”‚   â”‚
â”‚  â”‚ Dashboard â”‚  â”‚ (FastAPI)â”‚  â”‚ Scripts  â”‚  â”‚ (AI Agents)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚             â”‚             â”‚               â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PipelineFacade                              â”‚
â”‚                  (Single entry point)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Service Layer                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Ingestion    â”‚  â”‚ Extraction   â”‚  â”‚ Verification â”‚          â”‚
â”‚  â”‚ Service      â”‚  â”‚ Service      â”‚  â”‚ Service      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Engines + Repositories + Clients                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Verificationâ”‚ â”‚ Financial    â”‚  â”‚ FMP Client â”‚              â”‚
â”‚  â”‚ Engine     â”‚  â”‚ Data Repo    â”‚  â”‚ (API)      â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Claim      â”‚  â”‚ Claim Repo   â”‚  â”‚ LLM Client â”‚              â”‚
â”‚  â”‚ Extractor  â”‚  â”‚              â”‚  â”‚ (Claude)   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Domain Layer (Pure business rules)                  â”‚
â”‚         Verdicts â€¢ Scoring â€¢ Metrics (zero dependencies)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Database (SQLite / Postgres)                     â”‚
â”‚  Companies â€¢ Transcripts â€¢ Claims â€¢ Verifications â€¢ Patterns     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Clean 6-Layer Architecture

```
Presentation (UI/API/CLI/MCP)
    â†“
Facade (Single entry point)
    â†“
Services (Orchestration)
    â†“
Engines + Repos + Clients (Business logic + Data + External APIs)
    â†“
Domain (Pure rules, zero dependencies)
    â†“
Infrastructure (Database, ORM, Config)
```

### Key Patterns

- **Facade Pattern** - Single entry point, hides complexity
- **Repository Pattern** - Database abstraction (easy to swap SQLite â†’ Postgres)
- **Dependency Injection** - Clean testing, loose coupling
- **Domain-Driven Design** - Business rules isolated from infrastructure
- **Versioned Prompts** - LLM prompts in files, not hardcoded

### Why This Architecture?

1. **Testability** - Business logic tested without database/APIs (230 tests run in <2s)
2. **Flexibility** - Swap implementations without breaking other layers
3. **Clarity** - Bug in verdicts? Check `domain/verdicts.py` (30 lines, not 3000)

**Full details:** See [ARCHITECTURE_GUIDE.md](docs/ARCHITECTURE_GUIDE.md)

---

## Development

### Local Setup (Without Docker)

```bash
cd backend

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure API keys
cp .env.example .env
# Edit .env with your keys

# Run pipeline
python -m scripts.run_pipeline

# Launch UI
streamlit run streamlit_app.py
```

### Adding a New Company

```bash
# Option 1: Run pipeline for specific ticker
docker compose run streamlit python -m scripts.run_pipeline --tickers TSLA

# Option 2: Add to default list
# Edit app/config.py â†’ target_tickers list
```

### Database Migrations

```bash
# Check current migration status
alembic current

# Create new migration after model changes
alembic revision --autogenerate -m "add new column"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1
```

**More details:** See [docs/SETUP_GUIDE.md](docs/SETUP_GUIDE.md#5-database-migrations)

### Testing

```bash
# Unit tests only (fast)
pytest tests/unit/

# Integration tests (requires API keys)
pytest -m integration

# Specific test file
pytest tests/unit/test_verification_engine.py -v

# With coverage
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

---

## Documentation

| File | Purpose |
|------|---------|
| **README.md** | This file - quick overview and getting started |
| **[docs/ARCHITECTURE_GUIDE.md](docs/ARCHITECTURE_GUIDE.md)** | Deep dive: 6-layer architecture, design decisions, production features |
| **[docs/SETUP_GUIDE.md](docs/SETUP_GUIDE.md)** | Setup, deployment, database migrations, troubleshooting |
| **[docs/API_USAGE_GUIDE.md](docs/API_USAGE_GUIDE.md)** | REST API guide with curl/Python/JavaScript examples |
| **[docs/MCP_GUIDE.md](docs/MCP_GUIDE.md)** | AI agent integration (Claude Code, Cursor) |

---

## MCP Server (AI Agent Integration)

Expose claim auditor as tools for AI agents (Claude Code, Cursor, custom agents).

**Quick start:**
```bash
cd backend
python mcp_server.py
```

**Available tools:**
- `list_companies()` - Get all companies with trust scores
- `analyze_company(ticker)` - Full analysis
- `get_claims(ticker, verdict?)` - Claims with optional filtering
- `compare_quarters(ticker)` - Quarter-by-quarter trends
- `get_discrepancy_patterns(ticker)` - Systematic bias detection
- `run_pipeline(tickers, steps)` - Execute pipeline

**Full setup:** See [MCP_GUIDE.md](docs/MCP_GUIDE.md) for configuration, usage examples, and troubleshooting.

---

## For Reviewers

### Trade-offs Made

| Decision | Why | Alternative Considered |
|----------|-----|----------------------|
| SQLite vs Postgres | Dev simplicity, easy to demo | Postgres for production scale |
| Deterministic verification | Explainability, testing | LLM-based (inconsistent) |
| Local LLM for extraction | Claude API quality | Open-source (less accurate) |
| Pydantic 2.0 | Fast validation | Manual validation (error-prone) |

### What I'd Do Differently at Scale

**Infrastructure:**
- Postgres + connection pooling (SQLite doesn't scale)
- Redis for distributed caching (in-memory doesn't work across processes)
- Celery for async pipeline (long-running tasks)
- Rate limiting on API (currently unlimited)
- Message queue (RabbitMQ/Kafka) for event-driven architecture

**Architecture & Code Quality:**
- Reduce architectural debt (current setup was rapidly prototyped)
- Async operations throughout (currently synchronous for simplicity)
- OpenRouter integration (one source for multiple LLM providers, easy model switching)
- More comprehensive per-file documentation (1:1 markdown for each Python file)

**Features & UX:**
- Custom React/Vue UI (currently using Streamlit for rapid development)
- UI-based company addition (currently CLI/script only)
- Real-time pipeline status updates (WebSocket)
- User authentication and multi-tenancy

---

## License

MIT

---

## Contact

For questions or feedback:
- Open an issue on GitHub
- Or reach out directly

---

**Built with:** Python â€¢ FastAPI â€¢ Streamlit â€¢ Claude AI â€¢ Docker
