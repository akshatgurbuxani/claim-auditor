# Architecture Deep Dive

**Complete guide to the Claim Auditor architecture, design decisions, and implementation details.**

This document explains every architectural decision, shows how layers interact.

---

## Table of Contents

1. [System Overview](#1-system-overview)
2. [6-Layer Architecture](#2-6-layer-architecture)
3. [Detailed Data Flow](#3-detailed-data-flow)
4. [File-to-Layer Mapping](#4-file-to-layer-mapping)
5. [Pipeline Execution Flow](#5-pipeline-execution-flow)
6. [Key Design Decisions](#6-key-design-decisions)
7. [Interface Architecture](#7-interface-architecture)
8. [Testing Strategy](#8-testing-strategy)
9. [Trade-offs](#9-trade-offs)

---

## 1. System Overview

### The Problem We Solve

**Context:** Company executives make 30-50 quantitative claims per earnings call.

**Challenge:** These claims can be:
- **Inaccurate** - Stated 15% growth, actual was 12.3%
- **Misleading** - Using non-GAAP figures, favorable rounding, GAAP mismatch
- **Systematically biased** - Consistent patterns across quarters

**Manual verification is impractical** - Requires cross-referencing multiple statements, unit conversions, and pattern detection.

### Our Solution

4-stage automated pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DATA SOURCES                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   FMP API (Free)     â”‚           â”‚  Local Files (.txt)  â”‚
    â”‚  âœ… Company Profile  â”‚           â”‚  ğŸ“ Transcripts      â”‚
    â”‚  âœ… Income Stmt      â”‚           â”‚                      â”‚
    â”‚  âœ… Cash Flow        â”‚           â”‚  (FMP API blocked    â”‚
    â”‚  âœ… Balance Sheet    â”‚           â”‚   on free tier)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                  â”‚
               â–¼                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: INGEST                                                  â”‚
â”‚  (app/services/ingestion_service.py)                            â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Fetch structured financial data from FMP API                 â”‚
â”‚  â€¢ Try FMP transcript API â†’ Falls back to local .txt files      â”‚
â”‚  â€¢ Store both in SQLite database                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   SQLite Database     â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ companies       â”‚  â”‚  â† FMP (profile)
               â”‚  â”‚  - ticker       â”‚  â”‚
               â”‚  â”‚  - name, sector â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ transcripts     â”‚  â”‚  â† Local .txt
               â”‚  â”‚  - full_text    â”‚  â”‚  (unstructured)
               â”‚  â”‚  - quarter/year â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ financial_data  â”‚  â”‚  â† FMP (statements)
               â”‚  â”‚  - revenue      â”‚  â”‚  (structured)
               â”‚  â”‚  - net_income   â”‚  â”‚
               â”‚  â”‚  - op_income    â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: EXTRACT                                                 â”‚
â”‚  (app/services/extraction_service.py)                           â”‚
â”‚                                                                  â”‚
â”‚  For each transcript in database:                               â”‚
â”‚  1. Read unstructured text: "Revenue was $170.8B, up 11% YoY"   â”‚
â”‚  2. Send to Claude AI (Anthropic API)                           â”‚
â”‚  3. Claude returns structured JSON:                             â”‚
â”‚     {                                                            â”‚
â”‚       "speaker": "Andy Jassy",                                   â”‚
â”‚       "claim_text": "Revenue was $170.8B...",                    â”‚
â”‚       "metric": "revenue",                                       â”‚
â”‚       "stated_value": 170800000000,                              â”‚
â”‚       "unit": "usd"                                              â”‚
â”‚     }                                                            â”‚
â”‚  4. Store claims in database                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   SQLite Database     â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ claims          â”‚  â”‚  â† Claude extraction
               â”‚  â”‚  - claim_text   â”‚  â”‚
               â”‚  â”‚  - speaker      â”‚  â”‚
               â”‚  â”‚  - metric       â”‚  â”‚
               â”‚  â”‚  - stated_value â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: VERIFY                                                  â”‚
â”‚  (app/services/verification_service.py)                         â”‚
â”‚                                                                  â”‚
â”‚  For each claim:                                                â”‚
â”‚  1. Get stated value from claim                                 â”‚
â”‚     Stated: $170.8B (what exec said)                            â”‚
â”‚  2. Get actual value from financial_data                        â”‚
â”‚     Actual: $213.4B (from FMP API)                              â”‚
â”‚  3. Calculate accuracy                                          â”‚
â”‚     accuracy = 1 - |stated - actual| / actual = 0.80 (80%)     â”‚
â”‚  4. Assign verdict                                              â”‚
â”‚     â‰¥98% â†’ Correct, â‰¥90% â†’ Mostly Correct,                     â”‚
â”‚     â‰¥80% â†’ Misleading, <80% â†’ Incorrect                        â”‚
â”‚  5. Store verification result                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   SQLite Database     â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ verifications   â”‚  â”‚  â† Computed
               â”‚  â”‚  - verdict      â”‚  â”‚
               â”‚  â”‚  - actual_value â”‚  â”‚
               â”‚  â”‚  - accuracy     â”‚  â”‚
               â”‚  â”‚  - explanation  â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: ANALYZE                                                 â”‚
â”‚  (app/services/analysis_service.py)                             â”‚
â”‚                                                                  â”‚
â”‚  Look for patterns across multiple quarters:                    â”‚
â”‚  â€¢ Consistent rounding up (>70% favor company)                  â”‚
â”‚  â€¢ Metric switching (different metrics each quarter)            â”‚
â”‚  â€¢ Increasing inaccuracy (accuracy declining)                   â”‚
â”‚  â€¢ GAAP shifting (switching GAAP/non-GAAP)                      â”‚
â”‚  â€¢ Selective emphasis (only positive metrics)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   SQLite Database     â”‚
               â”‚                       â”‚
               â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
               â”‚  â”‚ discrepancy_    â”‚  â”‚  â† Pattern detection
               â”‚  â”‚   patterns      â”‚  â”‚
               â”‚  â”‚  - pattern_type â”‚  â”‚
               â”‚  â”‚  - severity     â”‚  â”‚
               â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. 6-Layer Architecture

Our system follows **clean architecture principles** with strict layer separation:

### Layer Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: PRESENTATION                                       â”‚
â”‚ â€¢ FastAPI REST API  â€¢ Streamlit UI  â€¢ CLI  â€¢ MCP Server     â”‚
â”‚                                                             â”‚
â”‚ Responsibility: Handle requests, render responses           â”‚
â”‚ Dependencies: Only imports PipelineFacade                   â”‚
â”‚ Files: streamlit_app.py, app/main.py, mcp_server.py,       â”‚
â”‚        scripts/run_pipeline.py                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: FACADE (Integration Layer)                         â”‚
â”‚ â€¢ PipelineFacade: Single entry point for all clients        â”‚
â”‚ â€¢ Wires up services, repos, engines, clients                â”‚
â”‚ â€¢ Returns only plain dicts (never ORM models)               â”‚
â”‚                                                             â”‚
â”‚ Responsibility: Hide complexity, prevent coupling           â”‚
â”‚ Dependencies: Services, Repos, Engines                      â”‚
â”‚ Files: app/facade.py                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: SERVICE (Orchestration Layer)                      â”‚
â”‚ â€¢ IngestionService   â€¢ ExtractionService                    â”‚
â”‚ â€¢ VerificationService â€¢ AnalysisService                     â”‚
â”‚                                                             â”‚
â”‚ Responsibility: Coordinate workflows, handle transactions   â”‚
â”‚ Dependencies: Engines, Repos, Clients                       â”‚
â”‚ Files: app/services/*.py                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 4: DOMAIN (Business Logic Layer)                      â”‚
â”‚ Engines: ClaimExtractor, VerificationEngine,                â”‚
â”‚          DiscrepancyAnalyzer, MetricMapper                  â”‚
â”‚ Pure Functions: app/domain/{metrics, verdicts, scoring}.py  â”‚
â”‚                                                             â”‚
â”‚ Responsibility: Core algorithms, zero external dependencies â”‚
â”‚ Dependencies: Domain functions only                         â”‚
â”‚ Files: app/engines/*.py, app/domain/*.py                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 5: REPOSITORY (Data Access Layer)                     â”‚
â”‚ â€¢ BaseRepository (template method pattern)                  â”‚
â”‚ â€¢ CompanyRepo, ClaimRepo, VerificationRepo, etc.            â”‚
â”‚                                                             â”‚
â”‚ Responsibility: Abstract database operations                â”‚
â”‚ Dependencies: Models                                        â”‚
â”‚ Files: app/repositories/*.py                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 6: INFRASTRUCTURE                                     â”‚
â”‚ â€¢ SQLAlchemy ORM models  â€¢ HTTP clients (FMP, Anthropic)    â”‚
â”‚ â€¢ Database engine        â€¢ Configuration (Pydantic)         â”‚
â”‚                                                             â”‚
â”‚ Responsibility: External systems, persistence               â”‚
â”‚ Dependencies: None (lowest layer)                           â”‚
â”‚ Files: app/models/*.py, app/clients/*.py, app/database.py   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Dependency Flow

**Key principle:** Dependencies flow downward only.

```
Presentation â†’ Facade â†’ Services â†’ Engines/Repos â†’ Domain/Infrastructure
```

**Never the reverse.** This ensures:
- **Testability** - Test each layer independently
- **Flexibility** - Swap implementations without breaking dependents
- **Clarity** - Bugs have a clear location

---

## 3. Detailed Data Flow

### Complete Request Flow Example

**User action:** "Analyze AMZN"

```
1. USER
   â”‚
   â”‚ Clicks button in Streamlit UI
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: streamlit_app.py           â”‚
â”‚                                      â”‚
â”‚ def show_company_details(ticker):    â”‚
â”‚     facade = get_facade()            â”‚
â”‚     data = facade.get_company_...    â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ facade.get_company_analysis("AMZN")
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: facade.py                  â”‚
â”‚                                      â”‚
â”‚ def get_company_analysis(ticker):    â”‚
â”‚     session = get_session()          â”‚
â”‚     service = AnalysisService(...)   â”‚
â”‚     result = service.analyze(...)    â”‚
â”‚     return result.to_dict()          â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ service.analyze_company(company_id)
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: analysis_service.py        â”‚
â”‚                                      â”‚
â”‚ def analyze_company(company_id):     â”‚
â”‚     # Get claims from database       â”‚
â”‚     claims = claim_repo.get(...)     â”‚
â”‚                                      â”‚
â”‚     # Run pattern detection          â”‚
â”‚     patterns = analyzer.analyze(...) â”‚
â”‚                                      â”‚
â”‚     # Calculate trust score          â”‚
â”‚     score = compute_trust_score(...) â”‚
â”‚                                      â”‚
â”‚     return Analysis(...)             â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”œâ”€â†’ claim_repo.get_for_company(company_id)
               â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   â”‚ LAYER 5: claim_repo.py           â”‚
               â”‚   â”‚                                  â”‚
               â”‚   â”‚ def get_for_company(id):         â”‚
               â”‚   â”‚     return session.query(Claim)  â”‚
               â”‚   â”‚       .filter_by(company_id=id)  â”‚
               â”‚   â”‚       .all()                     â”‚
               â”‚   â”‚                                  â”‚
               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â””â”€â†’ analyzer.analyze_company(claims)
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ LAYER 4: discrepancy_analyzer.py â”‚
                   â”‚                                  â”‚
                   â”‚ def analyze_company(claims):     â”‚
                   â”‚     patterns = []                â”‚
                   â”‚     patterns += detect_rounding()â”‚
                   â”‚     patterns += detect_switching()â”‚
                   â”‚     return patterns              â”‚
                   â”‚                                  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. File-to-Layer Mapping

This visual map shows **exactly** which files belong to which layer and **why**.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: PRESENTATION                                           â”‚
â”‚ "Where users interact"                                          â”‚
â”‚                                                                 â”‚
â”‚ streamlit_app.py     â†’ Web dashboard (humans click buttons)   â”‚
â”‚ app/main.py          â†’ REST API (programs make HTTP calls)    â”‚
â”‚ mcp_server.py        â†’ MCP server (AI agents connect)         â”‚
â”‚ scripts/run_pipeline.py â†’ CLI (terminal commands)             â”‚
â”‚                                                                 â”‚
â”‚ WHY SEPARATE? You can add a mobile app without touching       â”‚
â”‚               anything below this layer                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: FACADE                                                 â”‚
â”‚ "The simple menu"                                               â”‚
â”‚                                                                 â”‚
â”‚ app/facade.py        â†’ Single entry point, hides complexity   â”‚
â”‚                                                                 â”‚
â”‚ WHY SEPARATE? Provides a stable interface. Internal changes   â”‚
â”‚               don't break external clients                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: SERVICES                                               â”‚
â”‚ "The coordinators"                                              â”‚
â”‚                                                                 â”‚
â”‚ app/services/ingestion_service.py    â†’ Coordinates fetching   â”‚
â”‚ app/services/extraction_service.py   â†’ Coordinates extraction â”‚
â”‚ app/services/verification_service.py â†’ Coordinates verificationâ”‚
â”‚ app/services/analysis_service.py     â†’ Coordinates analysis   â”‚
â”‚                                                                 â”‚
â”‚ WHY SEPARATE? Services handle workflows and transactions.     â”‚
â”‚               They don't DO the work, they COORDINATE it       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 4A: ENGINES             â”‚ LAYER 4B: REPOSITORIES          â”‚
â”‚ "The workers"                 â”‚ "The database interface"        â”‚
â”‚                               â”‚                                 â”‚
â”‚ app/engines/claim_extractor.pyâ”‚ app/repositories/base.py        â”‚
â”‚   â†’ Extracts claims via LLM   â”‚   â†’ Generic CRUD operations     â”‚
â”‚                               â”‚                                 â”‚
â”‚ app/engines/verification_     â”‚ app/repositories/claim_repo.py  â”‚
â”‚   engine.py                   â”‚   â†’ Claim-specific queries      â”‚
â”‚   â†’ Core verification logic   â”‚                                 â”‚
â”‚   â†’ 400+ lines                â”‚ app/repositories/company_repo.pyâ”‚
â”‚                               â”‚   â†’ Company queries             â”‚
â”‚ app/engines/metric_mapper.py â”‚                                 â”‚
â”‚   â†’ Maps metrics to DB columnsâ”‚ app/repositories/verification_ â”‚
â”‚                               â”‚   repo.py                       â”‚
â”‚ app/engines/discrepancy_      â”‚   â†’ Verification queries        â”‚
â”‚   analyzer.py                 â”‚                                 â”‚
â”‚   â†’ Detects patterns          â”‚                                 â”‚
â”‚                               â”‚                                 â”‚
â”‚ WHY SEPARATE ENGINES?         â”‚ WHY SEPARATE REPOS?            â”‚
â”‚ Pure business logic that can  â”‚ Abstracts database access so   â”‚
â”‚ be tested without touching    â”‚ you can swap SQLite for        â”‚
â”‚ database or external APIs     â”‚ Postgres without changing      â”‚
â”‚                               â”‚ services or engines            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ calls
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 5: DOMAIN               â”‚ LAYER 4C: CLIENTS               â”‚
â”‚ "The pure rules"              â”‚ "The API wrappers"              â”‚
â”‚                               â”‚                                 â”‚
â”‚ app/domain/metrics.py         â”‚ app/clients/base_client.py      â”‚
â”‚   â†’ Metric definitions        â”‚   â†’ HTTP retry logic            â”‚
â”‚                               â”‚                                 â”‚
â”‚ app/domain/verdicts.py        â”‚ app/clients/fmp_client.py       â”‚
â”‚   â†’ Verdict assignment rules  â”‚   â†’ FMP API calls               â”‚
â”‚                               â”‚                                 â”‚
â”‚ app/domain/scoring.py         â”‚ app/clients/llm_client.py       â”‚
â”‚   â†’ Trust score formulas      â”‚   â†’ Claude API calls            â”‚
â”‚                               â”‚                                 â”‚
â”‚ WHY SEPARATE DOMAIN?          â”‚ WHY SEPARATE CLIENTS?          â”‚
â”‚ ZERO dependencies. These are â”‚ External APIs change. When FMP â”‚
â”‚ your business rules. Can test â”‚ updates, you only change this  â”‚
â”‚ with: assert verdict(.99)=="ok"â”‚ file. Core logic unaffected   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ uses
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 6: MODELS & SCHEMAS                                       â”‚
â”‚ "Data structures"                                               â”‚
â”‚                                                                 â”‚
â”‚ app/models/*.py              â†’ Database tables (SQLAlchemy ORM)â”‚
â”‚   - What you STORE                                             â”‚
â”‚   - company.py, claim.py, verification.py, etc.                â”‚
â”‚                                                                 â”‚
â”‚ app/schemas/*.py             â†’ API contracts (Pydantic)        â”‚
â”‚   - What you SEND/RECEIVE                                      â”‚
â”‚   - claim.py, verification.py, discrepancy.py                  â”‚
â”‚                                                                 â”‚
â”‚ WHY SEPARATE? Database structure â‰  API structure. You can     â”‚
â”‚               add DB columns without breaking API clients      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Pipeline Execution Flow

### Detailed Method Call Chain

When you run `python -m scripts.run_pipeline`:

```python
# scripts/run_pipeline.py
def main():
    facade = PipelineFacade()
    facade.run_pipeline(tickers=["AMZN"], steps="all")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 1: INGEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
facade.run_pipeline()
  â”œâ”€â†’ ingestion_service.ingest_company("AMZN")
  â”‚   â”œâ”€â†’ fmp_client.get_company_profile("AMZN")
  â”‚   â”‚   â”œâ”€ Check cache: data/fmp_cache/profile_AMZN.json
  â”‚   â”‚   â””â”€ If not cached: HTTP GET â†’ save to cache
  â”‚   â”‚
  â”‚   â”œâ”€â†’ company_repo.get_by_ticker("AMZN")
  â”‚   â”‚   â””â”€ If exists: skip, else: company_repo.create(...)
  â”‚   â”‚
  â”‚   â”œâ”€â†’ fmp_client.get_transcripts("AMZN", quarters)
  â”‚   â”‚   â”œâ”€ Try FMP API endpoint
  â”‚   â”‚   â””â”€ If fails: fallback to data/transcripts/AMZN_Q1_2025.txt
  â”‚   â”‚
  â”‚   â”œâ”€â†’ transcript_repo.get_by_ticker_quarter(AMZN, Q1, 2025)
  â”‚   â”‚   â””â”€ If exists: skip, else: transcript_repo.create(...)
  â”‚   â”‚
  â”‚   â”œâ”€â†’ fmp_client.get_income_statement("AMZN")
  â”‚   â”œâ”€â†’ fmp_client.get_cash_flow("AMZN")
  â”‚   â”œâ”€â†’ fmp_client.get_balance_sheet("AMZN")
  â”‚   â”‚   â””â”€ All cached in data/fmp_cache/
  â”‚   â”‚
  â”‚   â””â”€â†’ For each quarter:
  â”‚       â”œâ”€ Merge income/cash/balance data
  â”‚       â””â”€ financial_data_repo.create(revenue=155.7B, ...)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 2: EXTRACT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
facade.run_pipeline()
  â”œâ”€â†’ extraction_service.extract_all()
  â”‚   â”œâ”€â†’ transcript_repo.get_all() â†’ [transcript1, ...]
  â”‚   â”‚
  â”‚   â””â”€â†’ For each transcript:
  â”‚       â”œâ”€â†’ claim_repo.count_by_transcript(transcript.id)
  â”‚       â”‚   â””â”€ If > 0: skip (already extracted)
  â”‚       â”‚
  â”‚       â”œâ”€â†’ claim_extractor.extract(transcript.full_text)
  â”‚       â”‚   â”œâ”€â†’ prompt_manager.get_latest("claim_extraction")
  â”‚       â”‚   â”‚   â””â”€ Load app/prompts/templates/claim_extraction/v1.txt
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ llm_client.extract_claims(system, transcript)
  â”‚       â”‚   â”‚   â”œâ”€ Call Anthropic API
  â”‚       â”‚   â”‚   â””â”€ Return JSON array of claims
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ For each claim dict:
  â”‚       â”‚   â”‚  â”œâ”€ Validate with Pydantic (ClaimCreate)
  â”‚       â”‚   â”‚  â””â”€ If invalid: skip
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ Deduplicate (remove exact duplicates)
  â”‚       â”‚   â””â”€ Return [ClaimCreate, ...]
  â”‚       â”‚
  â”‚       â””â”€â†’ claim_repo.create_many(claims)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 3: VERIFY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
facade.run_pipeline()
  â”œâ”€â†’ verification_service.verify_all()
  â”‚   â”œâ”€â†’ claim_repo.get_unverified() â†’ [claim1, ...]
  â”‚   â”‚
  â”‚   â””â”€â†’ For each claim:
  â”‚       â”œâ”€â†’ verification_engine.verify(claim)
  â”‚       â”‚   â”œâ”€â†’ metric_mapper.can_resolve(claim.metric)
  â”‚       â”‚   â”‚   â””â”€ Check if "revenue" maps to DB column
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€ If unresolvable:
  â”‚       â”‚   â”‚  â””â”€ Return Verification(verdict="unverifiable")
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ metric_mapper.resolve(claim, financial_data)
  â”‚       â”‚   â”‚   â”œâ”€ For growth: fetch current + prior quarter
  â”‚       â”‚   â”‚   â”œâ”€ For margins: compute (numerator/denominator)
  â”‚       â”‚   â”‚   â””â”€ For absolute: get raw value
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ _normalize_stated_and_comparable(stated, actual)
  â”‚       â”‚   â”‚   â””â”€ Convert both to same unit (billions/millions)
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ accuracy_score(stated, actual)
  â”‚       â”‚   â”‚   â””â”€ 1 - |stated - actual| / |actual|
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ _check_misleading_flags(claim, actual)
  â”‚       â”‚   â”‚   â”œâ”€ Rounding bias?
  â”‚       â”‚   â”‚   â”œâ”€ GAAP mismatch?
  â”‚       â”‚   â”‚   â””â”€ Segment flag?
  â”‚       â”‚   â”‚
  â”‚       â”‚   â”œâ”€â†’ assign_verdict(accuracy, flags)
  â”‚       â”‚   â”‚   â””â”€ domain/verdicts.py logic
  â”‚       â”‚   â”‚
  â”‚       â”‚   â””â”€ Generate explanation string
  â”‚       â”‚
  â”‚       â””â”€â†’ verification_repo.create(...)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEP 4: ANALYZE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
facade.run_pipeline()
  â””â”€â†’ analysis_service.analyze_all()
      â”œâ”€â†’ company_repo.get_all() â†’ [company1, ...]
      â”‚
      â””â”€â†’ For each company:
          â”œâ”€â†’ claim_repo.get_by_company(company.id)
          â”‚   â””â”€ Returns claims grouped by quarter
          â”‚
          â”œâ”€â†’ discrepancy_analyzer.analyze_company(claims_by_q)
          â”‚   â”œâ”€ _detect_rounding_bias()
          â”‚   â”œâ”€ _detect_metric_switching()
          â”‚   â”œâ”€ _detect_increasing_inaccuracy()
          â”‚   â”œâ”€ _detect_gaap_shifting()
          â”‚   â””â”€ _detect_selective_emphasis()
          â”‚
          â”œâ”€â†’ pattern_repo.delete_for_company(company.id)
          â”‚   â””â”€ Remove old patterns
          â”‚
          â””â”€â†’ pattern_repo.create_many(patterns)
```

---

## 6. Key Design Decisions

### 1. Why Repository Pattern?

**Problem:** Services directly using SQLAlchemy queries.

**Bad (without repos):**
```python
# services/verification_service.py
def verify_all():
    claims = session.query(ClaimModel)\
        .filter(ClaimModel.verification == None)\
        .all()  # SQLAlchemy leaking into service
```

**Good (with repos):**
```python
# services/verification_service.py
def verify_all():
    claims = claim_repo.get_unverified()  # Clean abstraction
```

**Benefits:**
- Swap SQLite â†’ Postgres: change 1 file (repo), not 50 (services)
- Easy to mock for testing
- Single place to optimize queries
- Services don't know about database

### 2. Why Facade Pattern?

**Problem:** Presentation layer calling multiple services directly.

**Bad (without facade):**
```python
# streamlit_app.py
def show_analysis(ticker):
    company = CompanyRepository(db).get_by_ticker(ticker)
    claims = ClaimRepository(db).get_for_company(company.id)
    verifications = VerificationRepository(db).get_for_claims(claims)
    # ... 50 more lines of service coordination
```

**Good (with facade):**
```python
# streamlit_app.py
def show_analysis(ticker):
    data = facade.get_company_analysis(ticker)
    # Single call, simple interface
```

**Benefits:**
- Presentation layer doesn't know about internal structure
- Can refactor services without breaking UI/API
- Single integration point
- Easier to test

### 3. Why Separate Domain Layer?

**Problem:** Business rules mixed with infrastructure.

**Bad (mixed):**
```python
# verification_service.py
def verify(claim):
    # Business rule buried in service
    if accuracy >= 0.98:
        verdict = "correct"
    elif accuracy >= 0.90:
        verdict = "mostly_correct"
    # ...
```

**Good (separated):**
```python
# domain/verdicts.py (pure function)
def assign_verdict(accuracy_score):
    if accuracy_score >= 0.98:
        return "correct"
    elif accuracy_score >= 0.90:
        return "mostly_correct"
    # ...

# verification_service.py
def verify(claim):
    verdict = assign_verdict(accuracy)  # Use domain function
```

**Benefits:**
- Business rules testable without database/APIs
- Testing: `assert assign_verdict(0.99) == "correct"` (instant)
- Clear location for business logic
- Zero dependencies = maximum portability

### 4. Why Service Layer?

**Problem:** Business logic mixed with database operations and external API calls.

**Bad (without services):**
```python
# verification_engine.py - doing too much
def verify_all():
    # Database access in engine
    session = get_session()
    claims = session.query(Claim).filter_by(verified=False).all()

    # Business logic
    for claim in claims:
        result = self._calculate_accuracy(claim)

        # Database writes in engine
        session.add(Verification(claim_id=claim.id, ...))
    session.commit()  # Transaction management in wrong place
```

**Good (with services):**
```python
# verification_service.py - orchestrates
def verify_all(self):
    # Get data via repo
    claims = self.claim_repo.get_unverified()

    # Process via engine
    for claim in claims:
        result = self.engine.verify(claim)

        # Save via repo
        self.verification_repo.create(result)
    # Transaction boundary handled here
```

**Benefits:**
- **Transaction boundaries** - Services manage database transactions, not engines
- **Orchestration** - Coordinate multiple engines and repos
- **Error handling** - Centralized place for rollback logic
- **Workflow control** - Services know WHAT and WHEN, engines know HOW

Services are the orchestration layer. They coordinate workflows, manage transactions, and handle the sequence of operations. Engines have pure business logic, repos have data access, services tie them together.

---

### 5. Why Engine Layer?

**Problem:** Business logic mixed with orchestration logic.

**Bad (logic in services):**
```python
# verification_service.py - too much business logic
def verify(self, claim):
    # Complex business logic buried in service
    stated = claim.stated_value
    actual = self._get_actual_from_db(claim)

    # Normalization logic
    if claim.unit == "billions":
        stated *= 1_000_000_000

    # Calculation logic
    accuracy = 1 - abs(stated - actual) / abs(actual)

    # Verdict logic
    if accuracy >= 0.98:
        verdict = "correct"
    # ... 50 more lines of business logic
```

**Good (extracted to engine):**
```python
# verification_engine.py - pure business logic
def verify(self, claim: Claim, financial_data: FinancialData) -> Verification:
    actual = self.metric_mapper.resolve(claim, financial_data)
    normalized_stated, normalized_actual = self._normalize(stated, actual)
    accuracy = self._calculate_accuracy(normalized_stated, normalized_actual)
    flags = self._check_misleading_flags(claim, actual)
    verdict = assign_verdict(accuracy, flags)
    return Verification(verdict=verdict, accuracy=accuracy, ...)

# verification_service.py - simple orchestration
def verify_all(self):
    claims = self.claim_repo.get_unverified()
    for claim in claims:
        financial_data = self.financial_data_repo.get_for_claim(claim)
        result = self.engine.verify(claim, financial_data)  # Just call engine
        self.verification_repo.create(result)
```

**Benefits:**
- **Testability** - Test business logic without database: `assert engine.verify(claim, data).verdict == "correct"`
- **Reusability** - Engine can be used by CLI, API, or batch jobs
- **Focus** - Engine focuses on HOW (algorithm), service focuses on WHAT (workflow)
- **No side effects** - Engines are pure: same inputs â†’ same outputs

Engines contain pure business logic with no side effects. They take inputs, apply algorithms, return outputs. Services call engines, but engines never call services or repos. This makes business logic independently testable without mocking infrastructure.

---

### 6. Why Separate Clients?

**Problem:** External API calls scattered throughout codebase.

**Bad (API calls in services):**
```python
# ingestion_service.py - HTTP calls directly in service
def ingest_company(self, ticker: str):
    # Service making HTTP calls
    response = requests.get(
        f"https://financialmodelingprep.com/api/v3/profile/{ticker}",
        params={"apikey": self.api_key}
    )
    data = response.json()

    # What if API changes? Have to update every service
```

**Good (wrapped in client):**
```python
# clients/fmp_client.py - encapsulated
class FMPClient:
    def get_company_profile(self, ticker: str) -> dict:
        return self._get(f"/profile/{ticker}")

    def _get(self, endpoint: str) -> dict:
        # Retry logic, caching, error handling centralized
        return self._retry_with_backoff(...)

# ingestion_service.py - clean
def ingest_company(self, ticker: str):
    profile = self.fmp_client.get_company_profile(ticker)
    # Service doesn't know about HTTP, retries, caching
```

**Benefits:**
- **Encapsulation** - API details hidden from services
- **Centralized logic** - Retry, caching, error handling in one place
- **Easy swapping** - Switch FMP to Yahoo Finance, change one file
- **Testing** - Mock client instead of HTTP calls

Clients wrap external APIs to isolate integration details. Services call `client.get_profile(ticker)`, not `requests.get(url)`. When external APIs change, you update one client, not ten services. Also centralizes retry logic and caching.

---

### 7. Why Models vs Schemas?

**Problem:** Exposing ORM models directly to API clients.

**Bad (ORM leakage):**
```python
# API returns ORM model directly
@app.get("/claims/{id}")
def get_claim(id: int):
    return ClaimModel.query.get(id)  # SQLAlchemy object exposed
```

**Good (schemas):**
```python
# API returns Pydantic schema
@app.get("/claims/{id}", response_model=ClaimWithVerification)
def get_claim(id: int):
    claim = claim_repo.get(id)
    return ClaimWithVerification.from_orm(claim)  # Controlled contract
```

**Benefits:**
- Database changes don't break API
- Control what clients see (hide internal fields)
- Validation at API boundary
- ORM implementation detail

---

### 8. Why This Layering (Not MVC)?

**Problem:** Traditional MVC doesn't scale for complex domains.

**MVC issues:**
```
Model (data + logic) â† Fat models with business logic
View (presentation)
Controller (request handling)
```

**Problems with MVC for this domain:**
- Models become "god objects" with too many responsibilities
- Business logic mixed with ORM concerns
- Hard to test (models tied to database)
- No clear place for orchestration

**Our layering:**
```
Presentation â†’ Facade â†’ Services â†’ Engines/Repos/Clients â†’ Domain â†’ Infrastructure
```

**Why better:**
- **Single Responsibility** - Each layer has one job
- **Testability** - Test each layer independently
- **Flexibility** - Swap implementations without breaking dependents
- **Clarity** - Bug in verification? Check VerificationEngine, not "Claim model"

MVC works for simple CRUD apps, but not for complex domains with orchestration, external APIs, and algorithmic logic. Clean architecture provides clear separation: services orchestrate, engines compute, repos persist. Each layer is independently testable and swappable.

---

### 9. Why Pydantic for Schemas?

**Decision:** Use Pydantic 2.0 for API contracts and validation.

**Why Pydantic:**
- **Fast validation** - Rust core, 10-50x faster than manual validation
- **Type safety** - Integrates with Python type hints
- **Auto-documentation** - FastAPI generates OpenAPI docs from Pydantic models
- **Serialization** - `.model_dump()`, `.model_dump_json()` built-in
- **Conversion** - `.from_orm()` converts SQLAlchemy models to Pydantic

**Alternative considered:** Dataclasses + manual validation
- Slower
- No auto-docs
- Have to write serialization logic

Pydantic provides fast validation, type safety, and auto-documentation. FastAPI generates OpenAPI specs from Pydantic schemas. The `.from_orm()` method cleanly converts database models to API contracts.

---

### 10. Why SQLAlchemy for Models?

**Decision:** Use SQLAlchemy 2.0 ORM for database access.

**Why SQLAlchemy:**
- **ORM benefits** - Write Python, not SQL (but can drop to SQL when needed)
- **Relationship management** - `claim.verification` auto-loads related objects
- **Migration support** - Alembic integrates seamlessly
- **Database agnostic** - Same code works for SQLite, Postgres, MySQL
- **Type hints** - SQLAlchemy 2.0 has full type support

**Alternative considered:** Raw SQL or asyncpg
- Pros: Faster, more control
- Cons: More boilerplate, harder to maintain relationships

SQLAlchemy provides ORM convenience while being database-agnostic. Repository pattern abstracts it anyway, so if we needed raw SQL for performance, we'd just change repository internals without touching services.

---

### 11. Why Deterministic Verification (Not LLM)?

**Decision:** Use algorithmic verification, not LLM-based.

**Why:**
- **Explainability** - Can show exact calculation
- **Consistency** - Same claim always gets same verdict
- **Testing** - Easy to write unit tests
- **Cost** - No API calls for verification (only extraction)

**Trade-off:** Less flexible than LLM (can't handle nuanced cases).

---

## 7. Interface Architecture

We have **4 interfaces**, all using the same backend:

```
The architecture has 3 interfaces:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI (run_pipeline.py)   â”‚â”€â”€â”
â”‚ Uses: facade directly   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit UI            â”‚â”€â”€â”¼â”€â”€â”€â†’â”‚ PipelineFacade   â”‚
â”‚ Uses: facade directly   â”‚  â”‚    â”‚ (single entry)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ REST API (app/main.py)  â”‚â”€â”€â”˜
â”‚ Uses: dependencies.py   â”‚
â”‚       schemas/*.py      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCP Server              â”‚â”€â”€â”€â†’ Also uses PipelineFacade
â”‚ (AI agent integration)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Multiple Interfaces?

1. **CLI** - For pipeline execution, automation
2. **Streamlit** - For human exploration (visual dashboard)
3. **REST API** - For programmatic access (other systems)
4. **MCP Server** - For AI agent integration (Claude Code, Cursor)

**Key insight:** Same backend, different "faces". Add a mobile app? Just another interface.

---

## 8. Testing Strategy

### Test Pyramid

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Integration â”‚  â† 2 tests (E2E pipeline, live API)
    â”‚   Tests     â”‚    Slow, expensive, brittle
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”Œâ”€â”€â”€â”´â”€â”€â”€â”
       â”‚  Unit â”‚      â† 228 tests (<2s runtime)
       â”‚ Tests â”‚        Fast, cheap, reliable
       â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Testing Each Layer

**Domain layer (easiest):**
```python
def test_assign_verdict():
    assert assign_verdict(0.99) == "correct"
    assert assign_verdict(0.85) == "mostly_correct"
    # Pure functions = instant tests
```

**Engine layer:**
```python
def test_verification_engine(mock_financial_data):
    engine = VerificationEngine(mock_mapper, mock_repo, settings)
    result = engine.verify(claim)
    assert result.verdict == "misleading"
    # Mocked dependencies, tests logic only
```

**Service layer:**
```python
def test_verification_service(in_memory_db, mock_engine):
    service = VerificationService(mock_engine, claim_repo, verification_repo)
    service.verify_all()
    # Tests orchestration, not business logic
```

**Integration tests:**
```python
@pytest.mark.integration
def test_full_pipeline():
    # Requires: real database, real API keys
    facade.run_pipeline(tickers=["AAPL"], steps="all")
    # Tests everything together
```

### Why This Works

- **230 tests run in <2 seconds** (all unit tests)
- Integration tests skipped by default (`pytest -m integration` to run)
- Can test business logic without database/APIs
- Services tested with mocks
- Presentation tested against facade

---

## 9. Trade-offs

### SQLite vs Postgres

**Decision:** SQLite for development

**Why:**
- Zero configuration
- File-based (easy to share/demo)
- Good enough for <100K records

**Trade-off:**
- Doesn't scale (no concurrent writes)
- No advanced features (full-text search, JSON operators)

**Production path:** Swap to Postgres (only change: connection string in config)

### Deterministic vs LLM Verification

**Decision:** Algorithmic verification

**Why:**
- Explainable (show calculation)
- Testable (unit tests)
- Consistent (same result every time)
- Free (no API calls)

**Trade-off:**
- Less flexible (can't handle edge cases)
- Requires explicit rules

### Local Transcripts vs API

**Decision:** Fallback to local .txt files

**Why:**
- FMP transcript endpoint restricted on free tier
- Still demonstrates full pipeline

**Trade-off:**
- Manual transcript creation
- Doesn't scale to many companies

**Production path:** Pay for FMP Pro or use alternative API

### Monolith vs Microservices

**Decision:** Monolith

**Why:**
- Simple deployment (one container)
- No network overhead
- Easier to develop/debug

**Trade-off:**
- Can't scale services independently
- All-or-nothing deployment

**Production path:** Split into services (ingestion, extraction, verification) when traffic justifies it

---

## 10. Future Improvements

### Infrastructure Improvements

**Database & Caching:**
- **Postgres with connection pooling** - SQLite doesn't support concurrent writes; Postgres scales horizontally
- **Redis for distributed caching** - Current in-memory cache doesn't work across processes
- **Connection pooling** - Reuse database connections for better performance

**Async & Performance:**
- **Celery task queue** - Run pipeline steps asynchronously, enable parallel processing
- **Async/await throughout** - Currently synchronous for simplicity; async improves throughput
- **Message queue (RabbitMQ/Kafka)** - Decouple services for better scalability

**Operations:**
- **Structured logging (JSON)** - Enable log aggregation with ELK/Datadog
- **Rate limiting** - Protect API from abuse (currently unlimited)
- **Secret management** - Use Vault/AWS Secrets Manager instead of .env files
- **Health checks & metrics** - Prometheus/Grafana for monitoring

### Architecture Improvements

**Code Quality:**
- **Reduce architectural debt** - Refactor components that were rapidly prototyped
- **1:1 documentation** - Markdown file for each Python module with detailed explanations
- **Type hints coverage** - Ensure 100% type annotation for better IDE support
- **More granular error types** - Custom exceptions for different failure modes

**LLM Flexibility:**
- **OpenRouter integration** - Single interface for multiple LLM providers (Claude, GPT-4, Gemini)
- **Model switching** - Easy A/B testing between models via config
- **Prompt versioning** - Track prompt performance over time
- **Fallback models** - If Claude is down, auto-switch to GPT-4

### Feature Improvements

**User Experience:**
- **Custom React/Vue UI** - Replace Streamlit with production-grade frontend
- **UI-based company addition** - Let users add companies via interface (currently CLI only)
- **Real-time updates** - WebSocket for live pipeline status
- **User authentication** - Multi-user support with role-based access

**Functionality:**
- **Scheduled pipeline runs** - Cron-based automatic updates
- **Email/Slack notifications** - Alert on pattern detection
- **Export to PDF/Excel** - Generate reports for analysts
- **Historical trend analysis** - Track company accuracy over years

### Deployment Improvements

**Scalability:**
- **Horizontal scaling** - Multiple API instances behind load balancer
- **Microservices split** - Separate extraction (CPU-heavy) from verification (I/O-bound)
- **CDN for static assets** - Faster UI loading
- **Database read replicas** - Separate read/write workloads

**Reliability:**
- **Automated backups** - Daily database snapshots to S3
- **Disaster recovery** - Multi-region deployment
- **Circuit breakers** - Graceful degradation when external APIs fail
- **Retry with exponential backoff** - Already implemented, but extend to all external calls

---

## Summary: Architecture in One Paragraph


I built a 6-layer clean architecture with strict separation of concerns. The presentation layer (UI/API/CLI/MCP) calls a facade, which coordinates services. Services orchestrate workflows using engines (business logic), repositories (data access), and clients (external APIs). The domain layer contains pure business rules with zero dependencies, making them instantly testable. This architecture provides three key benefits: testability (230 tests run in <2 seconds), flexibility (swap databases without touching business logic), and clarity (bugs have a specific layer location). Every separation decision serves one of these goals.

**Key numbers to remember:**
- 6 layers
- 4 interfaces
- 230 tests (<2s)
- 400+ lines in core verification algorithm
- 0 dependencies in domain layer
